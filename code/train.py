#!/usr/bin/env python3
"""
è®­ç»ƒè„šæœ¬ - æ¤ç‰©åˆ†ç±»æ¨¡å‹è®­ç»ƒï¼ˆGPUä¼˜åŒ–ç‰ˆï¼‰
"""
import os
import sys
import csv
import time
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from torch.cuda.amp import autocast, GradScaler
from PIL import Image, ImageFile

# å¤„ç†æˆªæ–­å›¾åƒæ–‡ä»¶
ImageFile.LOAD_TRUNCATED_IMAGES = True

# æ·»åŠ å½“å‰ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from model import create_model
from utils import Config, setup_logging, get_transform, create_label_mapping, save_config

class PlantDataset:
    """æ¤ç‰©å›¾åƒæ•°æ®é›†"""
    
    def __init__(self, img_dir, label_file, transform=None):
        self.img_dir = img_dir
        self.img_labels = []
        self.transform = transform
        self.label_mapping = {}
        self.reverse_mapping = {}
        
        # åˆ›å»ºæ ‡ç­¾æ˜ å°„
        self.label_mapping, self.reverse_mapping = create_label_mapping(label_file)
        
        # è¯»å–æ ‡ç­¾æ–‡ä»¶
        with open(label_file, 'r', encoding='utf-8') as f:
            reader = csv.reader(f)
            next(reader)  # è·³è¿‡å¤´éƒ¨
            for row in reader:
                if len(row) >= 2:
                    img_name, label = row[0], int(row[1])
                    img_path = os.path.join(img_dir, img_name)
                    if os.path.exists(img_path):
                        # åº”ç”¨æ ‡ç­¾æ˜ å°„
                        mapped_label = self.label_mapping[label]
                        self.img_labels.append((img_name, mapped_label))
        
        self.logger = setup_logging()
        self.logger.info(f"âœ… åŠ è½½äº† {len(self.img_labels)} ä¸ªè®­ç»ƒæ ·æœ¬")
    
    def __len__(self):
        return len(self.img_labels)
    
    def __getitem__(self, idx):
        img_name, label = self.img_labels[idx]
        img_path = os.path.join(self.img_dir, img_name)
        
        try:
            image = Image.open(img_path).convert('RGB')
            if self.transform:
                image = self.transform(image)
            return image, label
        except Exception as e:
            self.logger.warning(f"âš ï¸ åŠ è½½å›¾åƒå¤±è´¥ {img_path}: {e}")
            # è¿”å›ä¸€ä¸ªç©ºç™½å›¾åƒ
            return torch.zeros(3, 224, 224), label

def train():
    """è®­ç»ƒå‡½æ•°"""
    logger = setup_logging()
    logger.info("ğŸš€ å¼€å§‹è®­ç»ƒæ¤ç‰©åˆ†ç±»æ¨¡å‹...")
    
    # é…ç½®å‚æ•°
    config = Config()
    
    # åˆ›å»ºæ•°æ®é›†
    dataset = PlantDataset(
        img_dir='/workspace/train',
        label_file='/workspace/train_labels00000.csv',
        transform=get_transform(config.img_size, is_train=True)
    )
    
    if len(dataset) == 0:
        logger.error("âŒ æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆæ•°æ®ï¼Œè®­ç»ƒç»ˆæ­¢")
        return
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨ï¼ˆä¼˜åŒ–GPUä½¿ç”¨ç‡ï¼‰
    dataloader = DataLoader(
        dataset,
        batch_size=config.batch_size * 4,  # å¢åŠ æ‰¹å¤„ç†å¤§å°
        shuffle=True,
        num_workers=8,  # å¢åŠ æ•°æ®åŠ è½½çº¿ç¨‹
        pin_memory=True,  # å¯ç”¨å†…å­˜é”å®š
        persistent_workers=True,  # ä¿æŒå·¥ä½œè¿›ç¨‹
        prefetch_factor=2  # é¢„å–å› å­
    )
    
    # åˆ›å»ºæ¨¡å‹
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    model = create_model(config.to_dict())
    model = model.to(device)
    
    # ä¼˜åŒ–å™¨å’ŒæŸå¤±å‡½æ•°
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=config.learning_rate, weight_decay=1e-4)
    
    # æ··åˆç²¾åº¦è®­ç»ƒ
    scaler = GradScaler() if device.type == 'cuda' else None
    
    # å­¦ä¹ ç‡è°ƒåº¦å™¨
    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)
    
    logger.info(f"ğŸ“Š è®­ç»ƒé…ç½®ï¼ˆGPUä¼˜åŒ–ç‰ˆï¼‰:")
    logger.info(f"  è®¾å¤‡: {device}")
    logger.info(f"  æ‰¹æ¬¡å¤§å°: {config.batch_size * 4}")
    logger.info(f"  å­¦ä¹ ç‡: {config.learning_rate}")
    logger.info(f"  æ€»è½®æ•°: {config.num_epochs}")
    logger.info(f"  ç±»åˆ«æ•°: {config.num_classes}")
    logger.info(f"  æ··åˆç²¾åº¦è®­ç»ƒ: {scaler is not None}")
    logger.info(f"  æ•°æ®åŠ è½½çº¿ç¨‹: 8")
    
    # è®­ç»ƒå¾ªç¯ï¼ˆGPUä¼˜åŒ–ï¼‰
    model.train()
    best_acc = 0.0
    
    for epoch in range(config.num_epochs):
        total_loss = 0
        correct = 0
        total = 0
        epoch_start_time = time.time()
        
        for batch_idx, (data, target) in enumerate(dataloader):
            batch_start_time = time.time()
            data, target = data.to(device, non_blocking=True), target.to(device, non_blocking=True)
            
            optimizer.zero_grad()
            
            # æ··åˆç²¾åº¦è®­ç»ƒ
            if scaler:
                with autocast():
                    output = model(data)
                    loss = criterion(output, target)
                scaler.scale(loss).backward()
                scaler.step(optimizer)
                scaler.update()
            else:
                output = model(data)
                loss = criterion(output, target)
                loss.backward()
                optimizer.step()
            
            total_loss += loss.item()
            _, predicted = output.max(1)
            total += target.size(0)
            correct += predicted.eq(target).sum().item()
            
            batch_time = time.time() - batch_start_time
            
            if batch_idx % 10 == 0:
                accuracy = 100. * correct / total if total > 0 else 0
                
                # GPUä½¿ç”¨ç‡ç›‘æ§ï¼ˆå®‰å…¨ç‰ˆæœ¬ï¼‰
                if device.type == 'cuda':
                    try:
                        gpu_memory = torch.cuda.memory_allocated() / 1024**3  # GB
                        # å®‰å…¨çš„GPUåˆ©ç”¨ç‡è·å–
                        gpu_util = 0
                        try:
                            import pynvml
                            pynvml.nvmlInit()
                            handle = pynvml.nvmlDeviceGetHandleByIndex(0)
                            gpu_util = pynvml.nvmlDeviceGetUtilizationRates(handle).gpu
                            pynvml.nvmlShutdown()
                        except:
                            gpu_util = 0
                        
                        logger.info(f'Epoch: {epoch+1}/{config.num_epochs}, '
                                  f'Batch: {batch_idx}/{len(dataloader)}, '
                                  f'Loss: {loss.item():.4f}, '
                                  f'Acc: {accuracy:.2f}%, '
                                  f'Time: {batch_time:.3f}s, '
                                  f'GPU: {gpu_memory:.1f}GB/{gpu_util}%')
                    except Exception as e:
                        logger.info(f'Epoch: {epoch+1}/{config.num_epochs}, '
                                  f'Batch: {batch_idx}/{len(dataloader)}, '
                                  f'Loss: {loss.item():.4f}, '
                                  f'Acc: {accuracy:.2f}%, '
                                  f'Time: {batch_time:.3f}s')
                else:
                    logger.info(f'Epoch: {epoch+1}/{config.num_epochs}, '
                              f'Batch: {batch_idx}/{len(dataloader)}, '
                              f'Loss: {loss.item():.4f}, '
                              f'Acc: {accuracy:.2f}%, '
                              f'Time: {batch_time:.3f}s')
        
        accuracy = 100. * correct / total
        avg_loss = total_loss / len(dataloader)
        epoch_time = time.time() - epoch_start_time
        
        # å­¦ä¹ ç‡è°ƒåº¦
        scheduler.step()
        current_lr = scheduler.get_last_lr()[0]
        
        # ä¿å­˜æœ€ä½³æ¨¡å‹
        if accuracy > best_acc:
            best_acc = accuracy
            os.makedirs('../model', exist_ok=True)
            torch.save(model.state_dict(), '../model/best_model.pth')
            
            # ä¿å­˜é…ç½®å’Œæ ‡ç­¾æ˜ å°„
            config_dict = config.to_dict()
            config_dict['label_mapping'] = {str(k): v for k, v in dataset.label_mapping.items()}
            config_dict['reverse_mapping'] = {str(k): v for k, v in dataset.reverse_mapping.items()}
            save_config(config_dict, '../model/config.json')
            logger.info(f"ğŸ’¾ ä¿å­˜æœ€ä½³æ¨¡å‹ï¼Œå‡†ç¡®ç‡: {accuracy:.2f}%")
            logger.info(f"ğŸ’¾ ä¿å­˜æ ‡ç­¾æ˜ å°„: {len(dataset.label_mapping)} ç±»æ˜ å°„åˆ° {len(set(dataset.label_mapping.values()))} ç±»")
        
        # GPUæ€§èƒ½ç»Ÿè®¡
        if device.type == 'cuda':
            gpu_memory = torch.cuda.max_memory_allocated() / 1024**3  # GB
            torch.cuda.reset_peak_memory_stats()
            logger.info(f'âœ… Epoch {epoch+1}å®Œæˆ - å¹³å‡æŸå¤±: {avg_loss:.4f}, å‡†ç¡®ç‡: {accuracy:.2f}%, '
                      f'æ—¶é—´: {epoch_time:.1f}s, å­¦ä¹ ç‡: {current_lr:.6f}, GPUå³°å€¼: {gpu_memory:.1f}GB')
        else:
            logger.info(f'âœ… Epoch {epoch+1}å®Œæˆ - å¹³å‡æŸå¤±: {avg_loss:.4f}, å‡†ç¡®ç‡: {accuracy:.2f}%, '
                      f'æ—¶é—´: {epoch_time:.1f}s, å­¦ä¹ ç‡: {current_lr:.6f}')
    
    logger.info(f"ğŸ‰ è®­ç»ƒå®Œæˆ! æœ€ä½³å‡†ç¡®ç‡: {best_acc:.2f}%")

if __name__ == "__main__":
    train()